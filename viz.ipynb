{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'feifang24/mtl-uncertainty-final'\n",
    "TASKS = ['sst', 'rte', 'mrpc']\n",
    "SPLITS = ['train', 'dev', 'test']\n",
    "AGG_METRICS = ['{split}_loss']\n",
    "METRIC_FORMATS = {\n",
    "                'loss': '{split}_loss_by_task/{task}', \n",
    "                'uncertainty': '{split}_uncertainty_by_task/{task}',\n",
    "                'acc': '{task}/{split}_ACC', # {dev, test} \n",
    "                'auc': '{task}/{split}_AUC', \n",
    "                'f1': '{task}/{split}_F1'\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "config_run_ids = defaultdict(list)\n",
    "for run in api.runs(path=PROJECT):\n",
    "    config_run_ids[run.name[:-2]].append(run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [api.run(f'{project}/{run_id}') for run_id in run_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_metrics_df = {}\n",
    "for config_name, run_ids in config_run_ids.items():\n",
    "    runs = [api.run(f'{project}/{run_id}') for run_id in run_ids]\n",
    "    avg_run = pd.concat([run.history() for run in runs])\n",
    "    avg_run = avg_run.groupby(level=0).mean()\n",
    "    config_metrics_df[config_name] = avg_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_metrics_df['sampling-smoothed-r=0.125'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "def plot_metric_over_time(split, metric, configs, plot_minima=False):\n",
    "    fig = go.Figure()\n",
    "    metric_format = METRIC_FORMATS[metric]\n",
    "    colors = px.colors.qualitative.Plotly\n",
    "    dashes = ['dash', 'dot', 'dashdot']\n",
    "    minima_x = {config: [] for config in configs}\n",
    "    minima_y = {config: [] for config in configs}\n",
    "    for i, task in enumerate(TASKS):\n",
    "        for j, config in enumerate(configs):\n",
    "            m = config_metrics_df[config][metric_format.format(split=split, task=task)]\n",
    "            fig.add_trace(go.Scatter(x=config_metrics_df[config].index, y=m,\n",
    "                                mode='lines',\n",
    "                                line=dict(color=colors[j], dash=dashes[i]),\n",
    "                                name=f'{config}/{task}'))\n",
    "            minima_x[config].append(m.idxmin())\n",
    "            minima_y[config].append(m.min())\n",
    "    if plot_minima:\n",
    "        for i, config in enumerate(configs):\n",
    "            fig.add_trace(go.Scatter(x=minima_x[config], y=minima_y[config], \n",
    "                                     mode='markers', \n",
    "                                     marker=dict(color=colors[i]),\n",
    "                                     name=f'{config} minimum'))\n",
    "    fig.update_layout(\n",
    "        yaxis_title=f'{split} {metric}'.title(),\n",
    "        xaxis_title=\"Iteration\",\n",
    "        legend_title=\"Method/Task\",\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_over_time('dev', 'loss', ['sampling-smoothed-r=0.375', 'sampling-smoothed-r=0.125', 'sampling-smoothed-r=0.5', 'sampling-smoothed-r=0.25'], plot_minima=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_over_time('train', 'loss', ['sampling-smoothed-r=0.375', 'sampling-smoothed-r=0.125', 'sampling-smoothed-r=0.5', 'sampling-smoothed-r=0.25'], plot_minima=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "def plot_heatmap(config):\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    colors = ['cadetblue', 'coral', 'olive']\n",
    "    for i, task in enumerate(TASKS):\n",
    "        m = config_metrics_df[config][METRIC_FORMATS['auc'].format(split='dev', task=task)]\n",
    "        fig.add_trace(go.Scatter(x=config_metrics_df[config].index, y=m,\n",
    "                                        mode='lines',\n",
    "                                        line=dict(color=colors[i]),\n",
    "                                        name=f'{task}'), row=1, col=1)\n",
    "    fig.add_trace(go.Heatmap(\n",
    "                       x=list(range(13)),\n",
    "                       z=[config_metrics_df[config][METRIC_FORMATS['uncertainty'].format(split='dev', task=task)].values for task in TASKS],\n",
    "                       y=TASKS,\n",
    "                       hoverongaps = False,\n",
    "                       colorscale='blues'), row=2, col=1)\n",
    "    fig.update_traces(colorbar_len=0.5, colorbar_yanchor=\"top\", selector=dict(type='heatmap'))\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Iteration\",\n",
    "        title=f'{config} AUC'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap('baseline-uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap('baseline-data-dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap('sampling-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap('sampling-smoothed-r=0.375')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, metrics_df in config_metrics_df.items():\n",
    "    print(config, end = \" & \")\n",
    "    for task in TASKS:\n",
    "        for metric in ['auc', 'acc', 'f1']:\n",
    "            dev_metric = config_metrics_df[config][METRIC_FORMATS[metric].format(split='dev', task=task)]\n",
    "            test_metric = config_metrics_df[config][METRIC_FORMATS[metric].format(split='test', task=task)]\n",
    "            print(round(test_metric.values[dev_metric.idxmax()], 2), end=\" & \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for config, metrics_df in config_metrics_df.items():\n",
    "    print(config)\n",
    "    for metric in ['auc', 'acc', 'f1']:\n",
    "        for task in TASKS:\n",
    "            dev_metric = config_metrics_df[config][METRIC_FORMATS[metric].format(split='dev', task=task)]\n",
    "            print(f\"{round(dev_metric.max(), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mtdnn]",
   "language": "python",
   "name": "conda-env-mtdnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
